import streamlit as st
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_teddynote.prompts import load_prompt
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages.chat import ChatMessage

# ì•± ì œëª© ë° ì„¤ëª… ì„¤ì •
st.title("ğŸ’¬ Chatbot")
st.caption("ğŸš€ A Streamlit chatbot powered by OpenAI")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "sessions" not in st.session_state:
    st.session_state.sessions = []


# ì‚¬ì´ë“œë°”ì— OpenAI API í‚¤ ì…ë ¥ í•„ë“œ ìƒì„±  :
with st.sidebar:
    clear_btn = st.button("Clear Chat")
    openai_api_key = st.text_input(
        "OpenAI API Key", key="chatbot_api_key", type="password"
    )
    selected_prompt = st.selectbox(
        "í”„ë¡¬í”„íŠ¸ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”",
        ("ê¸°ë³¸ëª¨ë“œ", "ì¸ìŠ¤íƒ€", "íŠ¸ìœ„í„°", "ë„¤ì´ë²„ ë¸”ë¡œê·¸", "ê¸°ìˆ  ë¸”ë¡œê·¸"),
        index=0,
    )
    st.markdown("---")
    st.subheader("ëŒ€í™” ì„¸ì…˜ ê´€ë¦¬")


# ì´ì „ ëŒ€í™”ë¥¼ ì¶œë ¥
def print_messages():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)


def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


def create_chain(prompt_type):
    # prompt | llm | output_parser
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒì˜ ì§ˆë¬¸ì— ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.",
            ),
            ("user", "#Question:\n{question}"),
        ]
    )
    if prompt_type == "ì¸ìŠ¤íƒ€":
        prompt = load_prompt("prompts/insta.yaml", encoding="utf-8")
    elif prompt_type == "íŠ¸ìœ„í„°":
        prompt = load_prompt("prompts/twitter.yaml", encoding="utf-8")

    elif prompt_type == "ë„¤ì´ë²„ ë¸”ë¡œê·¸":
        prompt = load_prompt("prompts/naver.yaml", encoding="utf-8")

    elif prompt_type == "ê¸°ìˆ  ë¸”ë¡œê·¸":
        prompt = load_prompt("prompts/tech_blog.yaml", encoding="utf-8")

    llm = ChatOpenAI(model_name="gpt-4o", temperature=0)

    # ì¶œë ¥íŒŒì„œ
    output_parser = StrOutputParser()

    chain = prompt | llm | output_parser
    return chain


# ì´ˆê¸°í™” ë²„íŠ¼ì´ ëˆŒë¦¬ë©´...
if clear_btn:
    st.session_state["messages"] = []


# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

user_input = st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input:
    st.chat_message("user").write(user_input)

    # chain ìƒì„±
    chain = create_chain(selected_prompt)

    response = chain.stream({"question": user_input})

    with st.chat_message("assistant"):
        container = st.empty()

        ai_answer = ""
        for token in response:
            ai_answer += token
            container.markdown(ai_answer)

    add_message("user", user_input)
    add_message("assistant", ai_answer)
