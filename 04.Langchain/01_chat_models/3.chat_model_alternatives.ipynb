{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë‹¤ì–‘í•œ chat modelë“¤ì„ ì‚¬ìš©í•´ë³´ê¸°\n",
    "\n",
    "- https://aistudio.google.com/app/apikey?hl=ko\n",
    "- https://console.anthropic.com/settings/keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Setup environment variables and messages\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "    ë„ˆëŠ” í•œêµ­ì˜ ê´€ê´‘ì§€ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ì•ˆë‚´í•˜ëŠ” ìµœê³ ì˜ ì—¬í–‰ê°€ì´ë“œì•¼. \n",
    "    í•œêµ­ì˜ ê´€ê´‘ì§€ì˜ ì—­ì‚¬, ë¬¸í™”, ìŒì‹ ë“±ì— ëŒ€í•´ ì˜ ì•Œê³  ìˆìœ¼ë©°, ê´€ê´‘ê°ë“¤ì—ê²Œ ìµœê³ ì˜ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³  ì‹¶ì–´í•´.\n",
    "    \"\"\"\n",
    "question = \"í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=question),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from OpenAI: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤. ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ì •ì¹˜, ê²½ì œ, ë¬¸í™”ì˜ ì¤‘ì‹¬ì§€ë¡œ, ì—­ì‚¬ì ìœ¼ë¡œë„ ì¤‘ìš”í•œ ë„ì‹œì…ë‹ˆë‹¤. \n",
      "\n",
      "ì„œìš¸ì€ ê³ ëŒ€ ì™•ì¡°ì¸ ì¡°ì„ ì˜ ìˆ˜ë„ì˜€ìœ¼ë©°, ê·¸ ìœ ì‚°ì´ ì˜¤ëŠ˜ë‚ ì—ë„ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ê²½ë³µê¶, ì°½ë•ê¶ê³¼ ê°™ì€ ì „í†µì ì¸ ê¶ê¶ì€ ë¬¼ë¡ , ë¶ì´Œ í•œì˜¥ë§ˆì„ê³¼ ì¸ì‚¬ë™ ê°™ì€ ì „í†µ ë¬¸í™” ê±°ë¦¬ë„ ë§ì€ ê´€ê´‘ê°ë“¤ì—ê²Œ ì‚¬ë‘ë°›ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë˜í•œ, ì„œìš¸ì€ í˜„ëŒ€ì ì¸ ë„ì‹œë¡œì„œ ê³ ì¸µ ë¹Œë”©, ì‡¼í•‘, ë§›ì§‘ ë“± ë‹¤ì–‘í•œ ì¦ê¸¸ ê±°ë¦¬ê°€ ê°€ë“í•©ë‹ˆë‹¤. ë§›ìˆëŠ” í•œêµ­ ìŒì‹, ì˜ˆë¥¼ ë“¤ì–´ ë¶ˆê³ ê¸°, ë¹„ë¹”ë°¥, ê¹€ì¹˜ì°Œê°œ ë“±ì„ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ì‹ë‹¹ë„ ë§ìŠµë‹ˆë‹¤. ì„œìš¸ì€ ì „í†µê³¼ í˜„ëŒ€ê°€ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ë§¤ë ¥ì ì¸ ë„ì‹œë¡œ, ë°©ë¬¸í•˜ëŠ” ëª¨ë“  ì´ë“¤ì—ê²Œ íŠ¹ë³„í•œ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ---- LangChain OpenAI Chat Model Example ----\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# Invoke the model with messages\n",
    "result = model.invoke(messages)\n",
    "print(f\"Answer from OpenAI: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from Anthropic: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤. \n",
      "\n",
      "ì„œìš¸ì€ 600ë…„ì´ ë„˜ëŠ” ì˜¤ëœ ì—­ì‚¬ë¥¼ ê°€ì§„ ë„ì‹œë¡œ, í˜„ëŒ€ì ì¸ ëª¨ìŠµê³¼ ì „í†µì´ ì¡°í™”ë¡­ê²Œ ê³µì¡´í•˜ëŠ” ë§¤ë ¥ì ì¸ ê³³ì…ë‹ˆë‹¤. ì¸êµ¬ ì•½ 1,000ë§Œ ëª…ì˜ ëŒ€ë„ì‹œë¡œ, í•œêµ­ì˜ ì •ì¹˜, ê²½ì œ, ë¬¸í™”ì˜ ì¤‘ì‹¬ì§€ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì„œìš¸ì˜ ì£¼ìš” ê´€ê´‘ì§€ë¡œëŠ”:\n",
      "\n",
      "1. ê²½ë³µê¶, ì°½ë•ê¶ ë“± ì¡°ì„  ì‹œëŒ€ì˜ ê¶ê¶\n",
      "2. ë‚¨ì‚°ì„œìš¸íƒ€ì›Œ\n",
      "3. ì¸ì‚¬ë™ê³¼ ë¶ì´Œí•œì˜¥ë§ˆì„ ë“± ì „í†µë¬¸í™” ì²´í—˜ ì¥ì†Œ\n",
      "4. ëª…ë™, ê°•ë‚¨ ë“± ì‡¼í•‘ê³¼ í˜„ëŒ€ ë¬¸í™”ë¥¼ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ì§€ì—­\n",
      "5. í•œê°•ê³µì›\n",
      "\n",
      "ë“±ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ì„œìš¸ì€ ë§›ìˆëŠ” í•œì‹ì„ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë ˆìŠ¤í† ë‘ê³¼ ê¸¸ê±°ë¦¬ ìŒì‹ìœ¼ë¡œë„ ìœ ëª…í•©ë‹ˆë‹¤.\n",
      "\n",
      "êµí†µì´ ë§¤ìš° ë°œë‹¬ë˜ì–´ ìˆì–´ ì§€í•˜ì² ê³¼ ë²„ìŠ¤ë¥¼ ì´ìš©í•´ ì‰½ê²Œ ì—¬í–‰í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ê³„ì ˆì´ ëšœë ·í•´ ê³„ì ˆë§ˆë‹¤ ë‹¤ë¥¸ ë§¤ë ¥ì„ ëŠë‚„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ---- Anthropic Chat Model Example ----\n",
    "\n",
    "# Create a Anthropic model\n",
    "# Anthropic models: https://docs.anthropic.com/en/docs/models-overview\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "\n",
    "result = model.invoke(messages)\n",
    "print(f\"Answer from Anthropic: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from Google: ì•ˆë…•í•˜ì„¸ìš”! í•œêµ­ì˜ ìˆ˜ë„ëŠ” **ì„œìš¸**ì…ë‹ˆë‹¤! ğŸ˜Š \n",
      "\n",
      "ì—­ë™ì ì¸ ë„ì‹œ ì„œìš¸ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ì„œìš¸ì€ í•œêµ­ì˜ ì‹¬ì¥ë¶€ì´ì 600ë…„ì´ ë„˜ëŠ” ì—­ì‚¬ë¥¼ ê°„ì§í•œ ë§¤ë ¥ì ì¸ ë„ì‹œì…ë‹ˆë‹¤.  ğŸ™ï¸âœ¨  \n",
      "\n",
      "ì„œìš¸ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ë©´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ì˜ˆë¥¼ ë“¤ì–´,  \n",
      "\n",
      "* ì„œìš¸ì˜ ì—­ì‚¬ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ì–´ìš”! ğŸ¯\n",
      "* ì„œìš¸ì—ì„œ ê¼­ ê°€ë´ì•¼ í•  ê³³ì€ ì–´ë””ì¸ê°€ìš”? ğŸ¤”\n",
      "* ì„œìš¸ì˜ ì „í†µ ìŒì‹ì„ ë§›ë³¼ ìˆ˜ ìˆëŠ” ìµœê³ ì˜ ì¥ì†ŒëŠ” ì–´ë””ì¸ê°€ìš”? ğŸ˜‹ \n",
      "\n",
      "ì €ëŠ” ì—¬ëŸ¬ë¶„ì˜ ì—¬í–‰ì„ ìµœê³ ë¡œ ë§Œë“¤ê¸° ìœ„í•´ ì´ê³³ì— ìˆìŠµë‹ˆë‹¤! ğŸ˜„ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- Google Chat Model Example ----\n",
    "# https://aistudio.google.com/app/apikey\n",
    "\n",
    "import os\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "result = model.invoke(messages)\n",
    "print(f\"Answer from Google: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# Upstage Chat Model\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "chat = ChatUpstage()\n",
    "response = chat.invoke(messages).content\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
